{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential outcomes: theory and application\n",
    "\n",
    "Sources:\n",
    "- causal inference mixtape \n",
    "- Imbens/Rubin 2015 \n",
    "- Imbens review article JEL\n",
    "- Dehejia/Wahba 2002 (DW2002). https://business.baylor.edu/scott_cunningham/teaching/dehejia-and-wahba-2002.pdf\n",
    "\n",
    "I slightly adjusted the comparisons what made most sense for me in the present context but have not compared them all to the original sources.\n",
    "Specifically, I tried to approximate as closely as possible a real situation where we do not have the experimental controls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context\n",
    "- What is the impact of training the unemployed?\n",
    "- Unemployed workers are not a random sample of the population. Normally we only have observational data (ie, labor market data, information on job training)\n",
    "- Lalonde 1986: conducts experiment among unemployed, and compares to existing methods with observational data\n",
    "- He found that existing methods performed poorly in recovering the true experimental effect from the observational data only\n",
    "- Dehejia/Wahba repeated Lalonde's analysis, but used (at the time) cutting-edge matching methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import statsmodels.api as sm \n",
    "import statsmodels.formula.api as smf \n",
    "from itertools import combinations \n",
    "import plotnine as p\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "from helpers import load_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsw_stacked = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treat</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>black</th>\n",
       "      <th>hisp</th>\n",
       "      <th>marr</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>earn74</th>\n",
       "      <th>earn75</th>\n",
       "      <th>earn78</th>\n",
       "      <th>randomised</th>\n",
       "      <th>unemp74</th>\n",
       "      <th>unemp75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16437.000000</td>\n",
       "      <td>16437.000000</td>\n",
       "      <td>16437.000000</td>\n",
       "      <td>16437.000000</td>\n",
       "      <td>16437.000000</td>\n",
       "      <td>16437.000000</td>\n",
       "      <td>16437.000000</td>\n",
       "      <td>16437.000000</td>\n",
       "      <td>16437.000000</td>\n",
       "      <td>16437.000000</td>\n",
       "      <td>16437.000000</td>\n",
       "      <td>16437.000000</td>\n",
       "      <td>16437.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.011255</td>\n",
       "      <td>33.012592</td>\n",
       "      <td>11.977916</td>\n",
       "      <td>0.094117</td>\n",
       "      <td>0.072458</td>\n",
       "      <td>0.697025</td>\n",
       "      <td>0.308998</td>\n",
       "      <td>13694.237305</td>\n",
       "      <td>13318.517578</td>\n",
       "      <td>14588.224609</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.136217</td>\n",
       "      <td>0.123928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.105495</td>\n",
       "      <td>11.030899</td>\n",
       "      <td>2.862478</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>0.259253</td>\n",
       "      <td>0.459558</td>\n",
       "      <td>0.462094</td>\n",
       "      <td>9675.637695</td>\n",
       "      <td>9372.831055</td>\n",
       "      <td>9702.608398</td>\n",
       "      <td>0.162301</td>\n",
       "      <td>0.343029</td>\n",
       "      <td>0.329509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3644.236084</td>\n",
       "      <td>3695.896973</td>\n",
       "      <td>5088.759766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14655.320312</td>\n",
       "      <td>14109.530273</td>\n",
       "      <td>15962.400391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23360.339844</td>\n",
       "      <td>22703.080078</td>\n",
       "      <td>25564.669922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39570.679688</td>\n",
       "      <td>25243.550781</td>\n",
       "      <td>60307.929688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              treat           age          educ         black          hisp  \\\n",
       "count  16437.000000  16437.000000  16437.000000  16437.000000  16437.000000   \n",
       "mean       0.011255     33.012592     11.977916      0.094117      0.072458   \n",
       "std        0.105495     11.030899      2.862478      0.292000      0.259253   \n",
       "min        0.000000     16.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000     24.000000     11.000000      0.000000      0.000000   \n",
       "50%        0.000000     31.000000     12.000000      0.000000      0.000000   \n",
       "75%        0.000000     42.000000     13.000000      0.000000      0.000000   \n",
       "max        1.000000     55.000000     18.000000      1.000000      1.000000   \n",
       "\n",
       "               marr      nodegree        earn74        earn75        earn78  \\\n",
       "count  16437.000000  16437.000000  16437.000000  16437.000000  16437.000000   \n",
       "mean       0.697025      0.308998  13694.237305  13318.517578  14588.224609   \n",
       "std        0.459558      0.462094   9675.637695   9372.831055   9702.608398   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000   3644.236084   3695.896973   5088.759766   \n",
       "50%        1.000000      0.000000  14655.320312  14109.530273  15962.400391   \n",
       "75%        1.000000      1.000000  23360.339844  22703.080078  25564.669922   \n",
       "max        1.000000      1.000000  39570.679688  25243.550781  60307.929688   \n",
       "\n",
       "         randomised       unemp74       unemp75  \n",
       "count  16437.000000  16437.000000  16437.000000  \n",
       "mean       0.027073      0.136217      0.123928  \n",
       "std        0.162301      0.343029      0.329509  \n",
       "min        0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.000000  \n",
       "50%        0.000000      0.000000      0.000000  \n",
       "75%        0.000000      0.000000      0.000000  \n",
       "max        1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsw_stacked.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>randomised</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>15992</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "randomised      0    1\n",
       "treat                 \n",
       "0.0         15992  260\n",
       "1.0             0  185"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(nsw_stacked[\"treat\"], nsw_stacked[\"randomised\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive difference in means\n",
    "\n",
    "- we take the treated from `nsw_dw` and the controls from `nsw_dw_cpscontrol` (ignore the controls from the experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The non-experimental difference in raw means is -8497.52\n"
     ]
    }
   ],
   "source": [
    "mask_treat = (nsw_stacked[\"treat\"] == 1) & (nsw_stacked[\"randomised\"] == 1)\n",
    "mask_control = (nsw_stacked[\"treat\"] == 0) & (nsw_stacked[\"randomised\"] == 0)\n",
    "\n",
    "yvar = \"earn78\"\n",
    "y1 = nsw_stacked.loc[mask_treat, yvar].mean()\n",
    "y0 = nsw_stacked.loc[mask_control, yvar].mean()\n",
    "\n",
    "te1 = y1 - y0\n",
    "\n",
    "\n",
    "print(f\"The non-experimental difference in raw means is {te1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This number is the same as in Dehejia/Wahba 2022, table 2, row 2, second-last column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental estimate\n",
    "\n",
    "We *do* have the experimental data, so let's see the estimate here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experimental difference in raw means is 1794.34\n"
     ]
    }
   ],
   "source": [
    "mask_treat = (nsw_stacked[\"treat\"] == 1) & (nsw_stacked[\"randomised\"] == 1)\n",
    "mask_control = (nsw_stacked[\"treat\"] == 0) & (nsw_stacked[\"randomised\"] == 1)\n",
    "\n",
    "yvar = \"earn78\"\n",
    "y1 = nsw_stacked.loc[mask_treat, yvar].mean()\n",
    "y0 = nsw_stacked.loc[mask_control, yvar].mean()\n",
    "\n",
    "te1 = y1 - y0\n",
    "\n",
    "\n",
    "print(f\"The experimental difference in raw means is {te1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample selection\n",
    "\n",
    "- discuss the formula/decomposition \n",
    "- could we just run a regression and control for the other observed characteristics?\n",
    "- yes, but the potential outcome approach has the following benefits:\n",
    "    - it makes us more aware of the required assumptions \n",
    "    - in some cases, regression may heavily interpolate between groups; using the methods discussed here puts some more hurdles that prevent us from blindly doing this\n",
    "- moreover, we can select the covariates $X$ without looking at the outcome $Y$\n",
    "    - this is also the foundation of the recent methods on \"doubly-robust learning\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propensity score\n",
    "\n",
    "- discuss the theorem \n",
    "- for discussing balance here, we'd need to match on closest neighbor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll ignore the experimental controls from now on.\n",
    "drop = (nsw_stacked[\"randomised\"] == 1) & (nsw_stacked[\"treat\"] == 0)\n",
    "nsw_stacked = nsw_stacked.loc[~drop, :].copy()\n",
    "\n",
    "mask_treat = nsw_stacked[\"treat\"] == 1\n",
    "mask_control = nsw_stacked[\"treat\"] == 0\n",
    "\n",
    "N_treat = nsw_stacked.loc[mask_treat, :].shape[0]\n",
    "N_control = nsw_stacked.loc[mask_control, :].shape[0]\n",
    "\n",
    "assert N_treat + N_control == nsw_stacked.shape[0], \"some units got lost\"\n",
    "\n",
    "\n",
    "# nsw_stacked.to_csv(\"mydf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimating propensity score\n",
    "logit_nsw = smf.glm(formula=\"\"\"treat ~ age + I(age**2) + I(age**3) + educ + I(educ**2) +\n",
    "                    marr + nodegree + black + hisp + earn74 + earn75\n",
    "                    + unemp74 + unemp75 + I(educ*earn74)\"\"\", \n",
    "                    family=sm.families.Binomial(),\n",
    "                   data=nsw_stacked).fit()\n",
    "\n",
    "nsw_stacked['pscore'] = logit_nsw.predict(nsw_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           pscore         age    nodegree        earn75\n",
      "count  185.000000  185.000000  185.000000    185.000000\n",
      "mean     0.425357   25.816216    0.708108   1532.055420\n",
      "std      0.307691    7.155019    0.455867   3219.250732\n",
      "min      0.001061   17.000000    0.000000      0.000000\n",
      "25%      0.132217   20.000000    0.000000      0.000000\n",
      "50%      0.400199   25.000000    1.000000      0.000000\n",
      "75%      0.670616   29.000000    1.000000   1817.284058\n",
      "max      0.938455   48.000000    1.000000  25142.240234\n",
      "             pscore           age      nodegree        earn75\n",
      "count  1.599200e+04  15992.000000  15992.000000  15992.000000\n",
      "mean   6.647637e-03     33.225239      0.295835  13650.803711\n",
      "std    4.166721e-02     11.045216      0.456432   9270.403320\n",
      "min    1.176785e-09     16.000000      0.000000      0.000000\n",
      "25%    1.927808e-05     24.000000      0.000000   4398.823242\n",
      "50%    1.187188e-04     31.000000      0.000000  14557.110352\n",
      "75%    9.633719e-04     42.000000      1.000000  22923.736816\n",
      "max    9.239787e-01     55.000000      1.000000  25243.550781\n"
     ]
    }
   ],
   "source": [
    "vars_to_compare = [\"pscore\", \"age\", \"nodegree\", \"earn75\"]\n",
    "print(nsw_stacked.loc[mask_treat, vars_to_compare].describe())\n",
    "print(nsw_stacked.loc[mask_control, vars_to_compare].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing propensity scores between treated and control groups**\n",
    "\n",
    "The propensity scores are highly imbalanced, and there are a lot of units in the control group whose propensity score is below the minimum in the treatment group.\n",
    "Since these units will not be contribute information to the estimation (they are not good \"counterfactuals\" because of their low propensity score), we drop them, like Dehejia/Wahba also did.\n",
    "\n",
    "**Others notes: Comparing control group to DW2002**\n",
    "- Same number of observations\n",
    "- For the control group, the mean propensity score differs from DW2002 (table 2, row 2).\n",
    "- But the other 3 variables displayed have the same means.\n",
    "- Thus, somehow the propensity score is misspecified relative to the original paper, but I don't know why.\n",
    "- (But the propensity scores for treatment and controls are the same as in Cunningham's book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16177, 15)"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsw_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15992, 15)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(nsw_stacked.loc[nsw_stacked[\"treat\"] == 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3856"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "12136"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pscore_threshold = nsw_stacked.loc[mask_treat, \"pscore\"].min()\n",
    "mask_pscore_threshold = nsw_stacked[\"pscore\"] >= pscore_threshold\n",
    "\n",
    "nsw_stacked = nsw_stacked.loc[mask_pscore_threshold, :].copy()\n",
    "\n",
    "# re-define the masks\n",
    "mask_treat = (nsw_stacked[\"treat\"] == 1) \n",
    "mask_control = (nsw_stacked[\"treat\"] == 0)\n",
    "\n",
    "\n",
    "display(sum(mask_control))\n",
    "display(15992 - sum(mask_control)) # this should be 11168 (DW002) or 12611 (DW1999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_hist(df, input_map, xlabel=\"Value\"):\n",
    "    \"Make a histogram of df, mapping over inputs in `input_map`.\"\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.title(\"Histogram of propensity score\")\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    for label, params in input_map.items():\n",
    "        x = df.loc[params[\"mask\"], \"pscore\"]\n",
    "        # Create histograms for each group\n",
    "        plt.hist(x, bins=20, density=True, alpha=0.7, color=params[\"color\"], label=label)\n",
    "\n",
    "        # Add legend\n",
    "        plt.legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_map = {\n",
    "    \"treat\": {\n",
    "        \"mask\": mask_treat,\n",
    "        \"color\": \"blue\"\n",
    "    },\n",
    "    \"control\": {\n",
    "        \"mask\": mask_control,\n",
    "        \"color\": \"orange\"\n",
    "    }\n",
    "}\n",
    "\n",
    "make_hist(nsw_stacked, plot_map, \"Propensity score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note on assessing balance\n",
    "- the propensity score is a nice summary of the balance, but makes assumptions about the functional form \n",
    "- common support -- see the assumptions for ATE (?)\n",
    "- alternatively, we can plot differences in means, normalized variances and overlap in the tails to compare the groups\n",
    "\n",
    ">Unlike CIA, the common support requirement is testable by simply plotting histograms or summarizing the data. Here we do that two ways: by looking at the summary statistics and by looking at a histogram. Let’s start with looking at a distribution in table form before looking at the histogram.\n",
    "\n",
    "\n",
    "\n",
    "note that independence $\\Rightarrow$ balance, so NOT balance $\\Rightarrow$ NOT independence. but balance is of course not sufficient for independence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have this huge imbalance. How can we fix it? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Propensity score theorem\n",
    "Assumptions\n",
    "- conditional independence -- $(Y^1, Y^0) \\perp\\!\\!\\!\\perp D | X $\n",
    "- common support, so that we can estimate $E[Y^i | X_i = x]$ for all $x$ and for all $i$\n",
    "\n",
    "Implication: conditioning on the propensity score is enough to recover the ATE $E[\\delta_i (X_i)]$. Common support is necessary in order to estimate the propensity score (why exactly?), and conditional independence is necessary for the propensity score to be sufficient for controlling for all confounding.\n",
    "\n",
    "Relation to the BLUE theorem in linear regression:\n",
    "- conditioning on all the relevant indepdendent variables is enough to give you an unbiased estimate of $\\beta$\n",
    "- but, moreover, we have collapsed the matrix of Xs into a single number\n",
    "\n",
    "**How can we use the propensity score**\n",
    "- Reweighting \n",
    "- Subclassification\n",
    "- Matching on the propensity score \n",
    "\n",
    "Imbens/Rubin prefer subclassification over reweighting because \n",
    "- propensity score is estimated with noise, and this enters the denominator in the reweighting schemes, creating bias \n",
    "- subclassification has smaller sampling variance because it smoothes over extreme values of the propensity score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll match on the log odds ratio instead of the propensity score directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "pscore = nsw_stacked.loc[:, \"pscore\"].copy()\n",
    "lps = np.log(pscore / (1 - pscore))\n",
    "nsw_stacked.loc[:, \"lps\"] = lps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching on the propensity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_treated = nsw_stacked.loc[mask_treat, :]\n",
    "df_controls = nsw_stacked.loc[mask_control, :]\n",
    "\n",
    "\n",
    "assert df_treated.index.is_unique\n",
    "assert df_controls.index.is_unique\n",
    "\n",
    "df_treated = df_treated.reset_index()\n",
    "df_controls = df_controls.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3856, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we'll use the indexes for tracking the matches\n",
    "treated = df_treated.loc[:, [\"index\", \"lps\"]].to_numpy() # we'll use the index to keep track of the \n",
    "controls = df_controls.loc[:, [\"index\", \"lps\"]].to_numpy()\n",
    "\n",
    "# sort from highest to lowest lps\n",
    "treated = treated[treated[:, 1].argsort()[::-1]] #https://stackoverflow.com/questions/26984414/efficiently-sorting-a-numpy-array-in-descending-order\n",
    "\n",
    "display(controls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matching without replacement\n",
    "matched = []\n",
    "k = 1 # number of matched control units\n",
    "for idx_treat in range(N_treat):\n",
    "    distance = (treated[idx_treat, 1] - controls[:, 1])**2\n",
    "    idx_min = np.argsort(distance)[:k]  # index of the min \n",
    "    idx_ctrl = controls[idx_min][:, 0] # index of the matched control\n",
    "\n",
    "    # update the pool of controls: drop the matched unit\n",
    "    mask = np.full(distance.shape, True)\n",
    "    mask[idx_min] = False\n",
    "    controls = controls[mask, ...]\n",
    "    \n",
    "    # add the matched control index to matched_controls\n",
    "    # matched += [(int(x), idx_treat) ]\n",
    "    matched += [(int(x), idx_treat) for x in idx_ctrl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(185, 17)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matched = pd.DataFrame(np.array(matched), columns=[\"idx_ctrl\", \"idx_treat\"])\n",
    "mask_pscore_control = df_controls[\"index\"].isin(matched[\"idx_ctrl\"]) \n",
    "display(sum(mask_pscore_control))\n",
    "display(df_treated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pscore</th>\n",
       "      <th>age</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>earn75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.298792</td>\n",
       "      <td>25.545946</td>\n",
       "      <td>0.616216</td>\n",
       "      <td>1781.612793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.218909</td>\n",
       "      <td>8.018274</td>\n",
       "      <td>0.487626</td>\n",
       "      <td>3396.027588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001062</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.132049</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.259063</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.411690</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2225.371094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.923979</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20268.240234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pscore         age    nodegree        earn75\n",
       "count  185.000000  185.000000  185.000000    185.000000\n",
       "mean     0.298792   25.545946    0.616216   1781.612793\n",
       "std      0.218909    8.018274    0.487626   3396.027588\n",
       "min      0.001062   16.000000    0.000000      0.000000\n",
       "25%      0.132049   19.000000    0.000000      0.000000\n",
       "50%      0.259063   24.000000    1.000000      0.000000\n",
       "75%      0.411690   30.000000    1.000000   2225.371094\n",
       "max      0.923979   55.000000    1.000000  20268.240234"
      ]
     },
     "execution_count": 748,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_controls.loc[mask_pscore_control, vars_to_compare].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated treatment effect: 1109.70\n"
     ]
    }
   ],
   "source": [
    "y1 = df_treated.loc[:, yvar].mean()\n",
    "y0 = df_controls.loc[mask_pscore_control, yvar].mean()\n",
    "te_pscore = y1 - y0\n",
    "print(f\"Estimated treatment effect: {te_pscore:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differences to DW2002\n",
    "\n",
    "- We get closer to the true causal effect, but are still quite far away\n",
    "- DW2002 performed much better still.\n",
    "- Our estimate is much smaller than theirs. \n",
    "- control group has different means across the variables displayed above, indicating that they are different set from the control units in DW2002\n",
    "- other things\n",
    "    - no indication here: https://cameron.econ.ucdavis.edu/mmabook/mma25p1treatment.txt\n",
    "    - double-checked the propensity score in R, but the formula should be correct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subclassification on the propensity score (unfinished)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to create blocks of observations in the treatment and control group that have similar propensity scores. Then, take the difference in the outcome within those groups, and average the differences across groups to get an estimate of the ATE. In other words, we assume that there as a block-randomized experiment where treatment assignment was random within each block.\n",
    "\n",
    "How do we find the blocks? Imbens/Rubin (chapter 17.3) propose the following algorithm\n",
    "1. Start with a single block, with boundaries equal to 0 and 1\n",
    "2. Compute 2 statistics to decide whether the block should be further splitted or not:\n",
    "    - Compute t-statistic testing the H0 that the average value of the propensity score is the same in treatment and control groups. \n",
    "    - Compute the number of observations in treatment and control groups that would remain in two new blocks created by splitting the current block at the median of the propensity score \n",
    "3. While t-statistic > threshold and new block sizes sufficiently large:\n",
    "    - Split the block\n",
    "    - Update the statistics above \n",
    "\n",
    "\n",
    "We need to define the following parameters\n",
    "- t_max = 1.96\n",
    "- the minimum number of treated or control units in a new block\n",
    "- the minimum number of units (T + C) in a new block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max = 1.96 \n",
    "N_min1 = 3 \n",
    "N_min2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treat</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>black</th>\n",
       "      <th>hisp</th>\n",
       "      <th>marr</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>earn74</th>\n",
       "      <th>earn75</th>\n",
       "      <th>earn78</th>\n",
       "      <th>randomised</th>\n",
       "      <th>unemp74</th>\n",
       "      <th>unemp75</th>\n",
       "      <th>pscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4041.000000</td>\n",
       "      <td>4041.000000</td>\n",
       "      <td>4041.000000</td>\n",
       "      <td>4041.00000</td>\n",
       "      <td>4041.000000</td>\n",
       "      <td>4041.000000</td>\n",
       "      <td>4041.000000</td>\n",
       "      <td>4041.000000</td>\n",
       "      <td>4041.000000</td>\n",
       "      <td>4041.000000</td>\n",
       "      <td>4041.000000</td>\n",
       "      <td>4041.000000</td>\n",
       "      <td>4041.000000</td>\n",
       "      <td>4041.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.045781</td>\n",
       "      <td>26.302649</td>\n",
       "      <td>10.976986</td>\n",
       "      <td>0.27419</td>\n",
       "      <td>0.122494</td>\n",
       "      <td>0.395942</td>\n",
       "      <td>0.514477</td>\n",
       "      <td>5473.653809</td>\n",
       "      <td>4194.241699</td>\n",
       "      <td>8144.358398</td>\n",
       "      <td>0.045781</td>\n",
       "      <td>0.374660</td>\n",
       "      <td>0.315516</td>\n",
       "      <td>0.045296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.209035</td>\n",
       "      <td>8.930160</td>\n",
       "      <td>2.245505</td>\n",
       "      <td>0.44616</td>\n",
       "      <td>0.327897</td>\n",
       "      <td>0.489112</td>\n",
       "      <td>0.499852</td>\n",
       "      <td>7058.390625</td>\n",
       "      <td>5671.688477</td>\n",
       "      <td>7938.381348</td>\n",
       "      <td>0.209035</td>\n",
       "      <td>0.484095</td>\n",
       "      <td>0.464779</td>\n",
       "      <td>0.132632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>196.537598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1775.095947</td>\n",
       "      <td>1620.241943</td>\n",
       "      <td>6408.950195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9708.166992</td>\n",
       "      <td>6409.354980</td>\n",
       "      <td>13549.269531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35040.070312</td>\n",
       "      <td>25243.550781</td>\n",
       "      <td>60307.929688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             treat          age         educ       black         hisp  \\\n",
       "count  4041.000000  4041.000000  4041.000000  4041.00000  4041.000000   \n",
       "mean      0.045781    26.302649    10.976986     0.27419     0.122494   \n",
       "std       0.209035     8.930160     2.245505     0.44616     0.327897   \n",
       "min       0.000000    16.000000     0.000000     0.00000     0.000000   \n",
       "25%       0.000000    19.000000    10.000000     0.00000     0.000000   \n",
       "50%       0.000000    24.000000    11.000000     0.00000     0.000000   \n",
       "75%       0.000000    31.000000    12.000000     1.00000     0.000000   \n",
       "max       1.000000    55.000000    18.000000     1.00000     1.000000   \n",
       "\n",
       "              marr     nodegree        earn74        earn75        earn78  \\\n",
       "count  4041.000000  4041.000000   4041.000000   4041.000000   4041.000000   \n",
       "mean      0.395942     0.514477   5473.653809   4194.241699   8144.358398   \n",
       "std       0.489112     0.499852   7058.390625   5671.688477   7938.381348   \n",
       "min       0.000000     0.000000      0.000000      0.000000      0.000000   \n",
       "25%       0.000000     0.000000      0.000000      0.000000    196.537598   \n",
       "50%       0.000000     1.000000   1775.095947   1620.241943   6408.950195   \n",
       "75%       1.000000     1.000000   9708.166992   6409.354980  13549.269531   \n",
       "max       1.000000     1.000000  35040.070312  25243.550781  60307.929688   \n",
       "\n",
       "        randomised      unemp74      unemp75       pscore  \n",
       "count  4041.000000  4041.000000  4041.000000  4041.000000  \n",
       "mean      0.045781     0.374660     0.315516     0.045296  \n",
       "std       0.209035     0.484095     0.464779     0.132632  \n",
       "min       0.000000     0.000000     0.000000     0.001061  \n",
       "25%       0.000000     0.000000     0.000000     0.002140  \n",
       "50%       0.000000     0.000000     0.000000     0.005382  \n",
       "75%       0.000000     1.000000     1.000000     0.015611  \n",
       "max       1.000000     1.000000     1.000000     0.938455  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsw_stacked.head()\n",
    "nsw_stacked.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll use the linearized propensity score instead \n",
    "# nsw_stacked[\"lps\"] = np.log(nsw_stacked[\"pscore\"])\n",
    "data = nsw_stacked.loc[:, [\"treat\", \"lps\"]].to_numpy()\n",
    "b = np.ones((data.shape[0],1))\n",
    "data = np.c_[data, b]\n",
    "\n",
    "# compute the t-stat\n",
    "W = data[:, 0] #treatment indicator\n",
    "\n",
    "def summarise(a, block, W):\n",
    "    \"\"\"In a block for group W, compute:\n",
    "    - the average propensity score\n",
    "    - the number of observations\n",
    "    - the within-group variance\n",
    "    \"\"\"\n",
    "    # TODO: there are assumptions on which columns are which variable\n",
    "    # perhaps just use vectors directly?\n",
    "\n",
    "    N = np.sum(block * W)\n",
    "    l = 1 / N * np.transpose(a[:, 1] * block).dot(W)\n",
    "    sum_of_squared_diff = np.sum((a[:, 2] * block - l)**2)\n",
    "\n",
    "    return l, N, sum_of_squared_diff\n",
    "\n",
    "l_1, N_1, s2_1 = summarise(data, block=data[:, 2], W=W)\n",
    "l_0, N_0, s2_0 = summarise(data, block=data[:, 2], W=np.ones(W.shape) - W)\n",
    "s_hat = 1 / (N_1 + N_0 - 2) * (s2_0 + s2_1)\n",
    "\n",
    "t_stat = (l_1 - l_0) / (np.sqrt(s_hat * (1 / N_1 + 1 / N_0)))\n",
    "\n",
    "# count number of observation in a block if split by the median propensity score \n",
    "mid = np.median(data[:, 1])\n",
    "block_a = data[:, 1] <= mid \n",
    "block_b = data[:, 1] > mid \n",
    "\n",
    "np.sum(data[:, 2] * block_a * W )\n",
    "np.sum(data[:, 2] * block_a * (np.ones(W.shape) - W) )\n",
    "\n",
    "np.sum(data[:, 2] * block_b * W )\n",
    "# np.sum(data[:, 2] * block_b * (np.ones(W.shape) - W) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # matching without replacement -- working code\n",
    "# matched = []\n",
    "# for idx_treat in range(N_treat):\n",
    "#     distance = (treated[idx_treat, 1] - controls[:, 1])**2\n",
    "#     idx_min = np.argmin(distance) # index of the min \n",
    "#     idx_ctrl = controls[idx_min][0] # index of the matched control\n",
    "#     # update the pool of controls: drop the matched unit\n",
    "#     mask = np.full(distance.shape, True)\n",
    "#     mask[idx_min] = False\n",
    "#     controls = controls[mask, ...]\n",
    "#     # add the matched control index to matched_controls\n",
    "#     matched.append((int(idx_ctrl), idx_treat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
